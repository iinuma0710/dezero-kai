# DeZero の実装 その1

## Step 1. 変数のひな型を作る
まずは、データを保持する「箱」となる変数 (Variable) を、Python のクラスで実装します。

```python
class Variable():
    def __init__(self, data):
        self.data = data
```

この ```Variable``` クラスを継承して、様々なデータを保持する「箱」を作っていきます。
今はデータを入れるだけですが、今後、データ形状などの属性値についても取得できるように改良していくことになると思います。

## Step 2. 関数のひな型を作る
関数 (Function) とは、ある変数と別の変数の対応関係を定めたものです。
入力としてある変数を受け取り、何らかの計算や変換をして別の変数を返します。
Python では ```def``` で関数を定義できますが、変数と同様に関数もクラスで実装します。

```python
class Function():
    def __call__(self, input):
        x = input.data
        y = self.forward(x)
        output = Variable(y)
        return output
    
    def forward(self, x):
        raise NotImplementedError()
```

```input``` 変数からデータを取り出して ```forward``` 関数で定義された処理を行い、その結果を ```output``` 変数に格納して返しています。
ただし、関数のひな型となる ```Function``` クラス内では処理の具体的な実装は行わず、以下に示すように ```Function``` クラスを継承したクラス内で実装します。

```python
class Square(Function):
    def forward(self, x):
        return x ** 2
```

## Step 3. 関数を連結する
上記の ```Square``` 関数クラスに加え、指数関数の計算をする ```Exp``` 関数クラスを実装し、$f(x)=(e^{x^2})^2$ を計算してみます。

```python
class Exp(Function):
    def forward(self, x):
        return np.exp(x)
    

A = Square()
B = Exp()
C = Square()

x = Variable(np.array(0.5))
a = A(x)
b = B(a)
y = C(b)
print(y.data)
```

```f = Function()``` のようにインスタンスを作成し、```f()``` とすることで ```__call__``` メソッドが呼ばれ、処理が実行されます。
各関数の入出力は ```Variable``` クラスで統一されているため、前段の出力を講談の入力につなげるだけで、関数の処理を連続的に実行できます。

## Step 4. 数値微分
関数 $f(x)$ の数学的な微分は以下の式で定義されます。

$$
f^{\prime}(x)=\lim_{h \to 0}\frac{f(x+h)-f(x)}{h}
$$

しかしながら、コンピュータで極限を計算することはできないので、$h=0.0001$ のような微小な値を用いて微分を計算します。
これを数値微分と呼び、誤差を抑制するために $f(x)$ の代わりに $f(x-h)$ とした中心差分近似を用います。
この方法では、ある $x$ における微分値は以下の式で表されます。

$$
f^{\prime}(x) \approx \frac{f(x+h)-f(x-h)}{2h}
$$

この式を Python の関数で表すと以下のようになります。

```python
def numerical_diff(f, x, eps=1e-4):
    x0 = Variable(x.data - eps)
    x1 = Variable(x.data + eps)
    y0 = f(x0)
    y1 = f(x1)
    return (y1.data - y0.data) / (2 * eps) 
```

数値微分で概ね正しい値を計算できますが、時として大きな誤差が生じ得ます。
また、変数ごとに微分を求める必要があるため、数百万のパラメータを持つ深層学習モデルでは計算コストが大きくなります。

## Step 5. 誤差逆伝播法 (Backpropagation) の理論
関数 $a = A(x)$、$b = B(a)$、$y = C(b)$ を合成した関数 $y = F(x) = C(B(A(x)))$ を考えます。 
この時、$y$ に関する $x$ の微分は以下の式で与えられます。(連鎖律、チェインルール)

$$
\frac{dy}{dx} = \frac{dy}{dy}\frac{dy}{db}\frac{db}{da}\frac{da}{dx}
$$

この式をよく観察すると、$\frac{dy}{db}=C^{\prime}(b)$、$\frac{db}{da}=B^{\prime}(a)$、$\frac{da}{dx}=A^{\prime}(x)$ なので、最終的な出力 $y$ の各変数 $b$、$a$、$x$ に関する微分を以下のように連鎖的に計算することができます。

$$
\begin{aligned}
\frac{dy}{db} &= \frac{dy}{dy}\frac{dy}{db} = C^{\prime}(b) \\
\frac{dy}{da} &= \frac{dy}{db}\frac{db}{da} = C^{\prime}(b)B^{\prime}(a) \\
\frac{dy}{dx} &= \frac{dy}{da}\frac{da}{dx} = C^{\prime}(b)B^{\prime}(a)A^{\prime}(x)
\end{aligned}
$$

このように、計算式を逆にたどりながら微分を計算することができ、関数を順番にたどって計算を行う順伝播に対して逆伝播と呼ばれます。
また、上式において $a$ や $b$ は関数 $A$ や $B$ の順伝播の出力であり、これらの値を逆伝播時に保持しておく必要があることがわかります。

# Step 6. 手作業による逆伝播
Step. 5 の逆伝播法を実装していきます。
まず、```Variable``` クラスに微分値を保持する属性 (アトリビュート) ```grad``` を追加します。
```grad``` は ```None``` で初期化し、逆伝播の際に計算した値を格納します。

```python
class Variable():
    def __init__(self, data):
        self.data = data
        # 微分値を保持する属性
        self.grad = None
```

次に、```Function``` クラスにも、次の2つの機能を追加します。

- 順伝播で入力値を保持する機能
- 逆伝播で微分値を計算する機能 (```backward``` メソッド)

```python
class Function():
    def __call__(self, input):
        x = input.data
        y = self.forward(x)
        output = Variable(y)
        # 入力された変数を保持する
        self.input = input
        return output
    
    def forward(self, x):
        raise NotImplementedError()
    
    # 逆伝播の計算を行う関数
    def backward(self, gx):
        raise NotImplementedError()
```

```forward``` メソッド同様、```backward``` メソッドについても具体的な実装は継承先のクラスに任せています。
そのため、これまでに実装した ```Square``` と ```Exp``` クラスに ```backward``` メソッドを追加します。
$y=x^2$ の微分が $\frac{dy}{dx}=2x$、$y=e^x$ の微分が $\frac{dy}{dx}=e^x$ であること、および先述の逆伝播の計算方法から。以下のように実装できます。

```python
class Square(Function):
    def forward(self, x):
        y = x ** 2
        return y
    
    def backward(self, gy):
        x = self.input.data
        gx = 2 * x * gy
        return gx
    

class Exp(Function):
    def forward(self, x):
        y = np.exp(x)
        return y
    
    def backward(self, gy):
        x = self.input.data
        gx = np.exp(x) * gy
        return gx
```

## Step 7. 逆伝播の自動化
Step 6 で逆伝播を実装しましたが、今の状態では ```forward``` メソッドの実行順と逆順になるよう、自分で ```backward``` メソッドを並べる必要があります。
これはミスの温床ですし何より退屈ですので、自動化を目指します。  
まずは、```Variable``` に ```creator``` 属性を追加します。
ある関数から出力された変数から見たとき、出力元の関数は「創造者 (creator)」です。
すなわち、変数の ```creator``` 属性に出力元の関数を保持し、変数と関数の接続関係を表現しています。

```python
class Variable():
    def __init__(self, data):
        self.data = data
        self.grad = None
        # 出力元の関数を保持する属性
        self.creator = None

    # creator 属性の setter
    def set_creator(self, func):
        self.creator = func
```

次に、```Function``` クラスにも手を加えます。
順伝播の演算時に、出力する変数の ```creator``` 属性に自分自身を設定します。
また、関数の入力だけでなく出力の変数についても保持するように変更します。

```python
class Function():
    def __call__(self, input):
        x = input.data
        y = self.forward(x)
        output = Variable(y)
        # 自分自身を出力する変数の creator に設定
        output.set_creator(self)
        self.input = input
        # 出力の変数も保持
        self.output = output
        return output
```

ここで、例えば $B^{\prime}(a)$ の微分値 ```a.grad``` は以下のように求められます。

```python
B = b.creator   # 1. 関数 B を取得
a = B.input     # 2. 関数 B の入力を取得
a.grad = B.backward(b.grad) # 3. 関数 B の backward で微分を計算
```

ほかの変数についても同様に微分の計算ができるので、上記のプログラムを実行する ```backward``` メソッドを ```Variable``` に追加します。

```python
class Variable():
    ...

    def backward(self):
        f = self.creator    # 1. 関数の取得
        if f is not None:
            x = f.input     # 2. 関数の入力を取得
            x.grad = f.backward(self.grad)  # 3. 関数の backward メソッド呼び出し
            x.backward()    # 再帰的に自分より一つ前の変数の backward メソッド呼び出し
```

以上で、```y.backward()``` を実行すれば ```x.grad``` まで自動で計算されるようになります。

## Step 8. Variable の backward メソッドについて
Step 7 では再帰的に ```Variable``` の ```backward``` メソッドを呼び出すことで微分を計算していました。
しかし、これでは枝分かれを含むような複雑なネットワークに対応するのが難しくなります。
そこで、```backward``` をループで実行するように実装を変更します。

```python
class Variable():
    ...

    def backward(self):
        funcs = [self.creator] 
        while funcs:    # 処理する関数がなくなるまで繰り返し
            f = funcs.pop()             # 関数を取得
            x, y = f.input, f.output    # 関数の入出力を取得
            x.grad = f.backward(y.grad) # backward メソッドの呼び出し
        
            if x.creator is not None:
                funcs.append(x.creator) # 1つ前の関数をリストに追加
```

## Step 9. ここまでのコードを改良する
### 関数クラスを関数として使う
ここまで実装したコードでは、関数クラスをインスタンスを生成したうえで、そのインスタンスに変数を渡して呼び出すという段階を踏んでいました。
しかし、これでは面倒なので関数クラスを Python の関数のように使えるように変更します。

```python
def square(x):
    return Square()(x)

def exp(x):
    return Exp()(x)
```

これで ```square(exp(square(x)))``` のような書き方もできるようになります。  

### backwarrd メソッドを変更する
```Variable``` の ```backwarrd``` メソッドを以下のように変更します。

```python
class Variable():
    ...

    def backward(self):
        if self.grad is None:
            # self.data と同じ形状で要素がすべて1の ndarray インスタンスを生成
            self.grad = np.ones_like(self.data)

        ...
```

今まで、逆伝播の計算を開始する際に、最終的に出力された変数の ```grad``` に1をセットしていましたが、その必要がなくなります。  

### データ型の制限
これまで、```Variable``` で保持する値の型は特に指定していませんでした。
しかし、今後の実装で任意のデータ型に対応するのは難しいので、```None``` と ```ndarray``` インスタンス以外のデータ型を取らないように制限を加えます。

```python
class Variable():
    def __init__(self, data):
        if data is not None:
            if not isinstance(data, np.ndarray):
                raise TypeError("{} is not supported".format(type(data)))
    ...
```

演算の結果が ```np.float64``` のようなスカラ型になってしまう可能性があるため、それを防ぐコードも追加します。
具体的には、スカラ型を判定して ```ndarray``` に変換する関数 ```as_array``` を用意し、```Function``` で出力変数に格納する際に適用するようにします。

```python
def as_array(x):
    if np.isscalar(x):
        return np.array(x)
    return x

class Function():
    def __call__(self, input):
        x = input.data
        y = self.forward(x)
        output = Variable(as_array(y))
        ...
```

## Step 10. テスト
標準ライブラリの ```unittest``` モジュールを用いて ```square``` 関数のテストを実装します。
具体的には、2.0 を入力したときに 4.0 が出力されることを確認します。

```python
class SquareTest(unittest.TestCase):
    def test_forward(self):
        x = Variable(np.array(2.0))
        y = square(x)
        expected = np.array(4.0)
        self.assertEqual(y.data, expected)
```

以下のようにテストを実行して ```OK``` と表示されればテスト通過です。

```bash
$ python -m unittest step10.py
.
----------------------------------------------------------------------
Ran 1 test in 0.001s

OK
```

さらに、```square``` 関数の逆伝播のテストも追加します。

```python
class SquareTest(unittest.TestCase):
    ...

    def test_backward(self):
        x = Variable(np.array(3.0))
        y = square(x)
        y.backward()
        expected = np.array(6.0)
        self.assertEqual(x.grad, expected)
```

ここで、勾配確認 (gradient checking) と呼ばれる方法で、逆伝播で求めた微分値を検証します。
この方法では、数値微分で求めた微分値と逆伝播で求めた微分値を比較することでテストを行います。

```python
class SquareTest(unittest.TestCase):
    ...

    def test_gradient_check(self):
        x = Variable(np.random.random(1))
        y = square(x)
        y.backward()
        num_grad = numerical_diff(square, x)
        flg = np.allclose(x.grad, num_grad)
        self.assertTrue(flg)
```

```np.allclose(a, b, rtol=1e-05, atol=1e-08)``` は、$|a-b| \leq atol + rtol * |b|$ を満たすときに ```True``` を返します。