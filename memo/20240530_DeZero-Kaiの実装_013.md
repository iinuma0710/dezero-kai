# DeZero-Kai の実装 その13

## Step 44. パラメータをまとめるレイヤ
Step 42 や Step 43 では、線形回帰や簡単なニューラルネットワークを実装しましたが、学習の際にパラメータを更新するコードを自前で書く必要がありました。
パラメータが少ないうちはこれでも良いのですが、今後、より複雑なネットワークを作成する際に、そのようなコードを書くのは面倒です。
そこで、このステップでは ```Parameter``` クラスと ```Layer``` クラスを実装し、パラメータの管理を自動化します。  
まずは、```Parameter``` クラスを実装します。

```dzrkai/core.py```
```python
class Parameter(Variable):
    pass
```

実体としては ```Variable``` クラスを継承しただけで、```Variable``` と ```Parameter``` は全く同じ機能を持ちます。
そのため、両者を組み合わせて計算できます。
しかし、```isinstance``` で区別することができるので、これを利用して ```Parameter``` だけをまとめる仕組みを作ることができます。  
次に ```Layer``` クラスを実装します。
```Function``` クラスと同様に機能を提供しますが、```Layer``` クラスはパラメータを保持し、パラメータを使った変換を行います。

```dzrkai/layers.py```
```python
from dzrkai.core import Parameter

class Layer:
    def __init__(self):
        self._params = set()

    def __setattr__(self, name, value):
        if isinstance(value, Parameter):
            self._params.add(name)
        super().__setattr__(name, value)
```

```__setattr__``` は、インスタンス変数を設定するたびに呼ばれる特殊メソッドです。
引数に ```name``` と ```value``` を設定しておくと、設定されたインスタンス変数の名前が ```name```に、値が ```value``` にそれぞれ渡されます。
```isinstance``` でインスタンス変数の型を判定し、```Parameter``` クラスのインスタンスが渡された場合にのみ、```self._params``` に追加します。  
次に、```Layer``` クラスに以下のメソッドを追加します。

```dzrkai/layers.py```
```python
import weakref

class Layer:
    ...

    def __call__(self, *inputs):
        outputs = self.forward(*inputs)
        if not isinstance(outputs, tuple):
            outputs = (outputs, )
        self.inputs = [weakref.ref(x) for x in inputs]
        self.outputs = [weakref.ref(y) for y in outputs]
        return outputs if len(outputs) > 1 else outputs[0]
    
    def forward(self, inputs):
        raise NotImplementedError()
    
    def params(self):
        for name in self._params:
            yield self.__dict__[name]

    def cleargrads(self):
        for param in self.params():
            param.cleargrad()
```

```__call__``` メソッドと ```forward``` メソッドは、ともに Function クラスの実装と共通です。
```params``` メソッドは、```Layer``` クラスのインスタンスが持つ ```Parameter``` インスタンスを取り出します。
また、```cleargrads``` メソッドでは各パラメータの ```cleargrad``` メソッドを呼び出して全てのパラメータの勾配をリセットします。  
それでは、```Layer``` クラスを継承して ```Linear``` クラスを実装してみましょう。
```Linear``` クラスは、出力サイズ ```out_size``` と、バイアスを使用するか否かを表すフラグ ```nobias``` を指定してインスタンスを作成します。
データを流すタイミングで重み ```W``` を生成することで、インスタンス化の際、明示的に入力サイズ ```in_size``` を指定しなくても良いようになっています。


```dzrkai/layers.py```
```python
class Linear(Layer):
    def __init__(self, out_size, nobias=False, dtype=np.float32, in_size=None):
        super().__init__()
        self.in_size = in_size
        self.out_size = out_size
        self.dtype = dtype

        self.W = Parameter(None, name='W')
        if self.in_size is not None:
            self._init_W()

        if nobias:
            self.b = None
        else:
            self.b = Parameter(np.zeros(out_size, dtype=dtype), name='b')

    def _init_W(self):
        I, O = self.in_size, self.out_size
        W_data = np.random.randn(I, O).astype(self.dtype) * np.sqrt(1 / I)
        self.W.data = W_data

    def forward(self, x):
        if self.W.data is None:
            self.in_size = x.shape[1]
            self._init_W()

        y = F.linear(x, self.W, self.b)
        return y
```

最後に、Step 43 と同じデータに対して、```Linear``` クラスを使ったニューラルネットワークを適用してみます。

```python
# 出力サイズのみを指定して Linear インスタンスを作成
l1 = L.Linear(10)
l2 = L.Linear(1)

def predict(x):
    y = l1(x)
    y = F.sigmoid(y)
    y = l2(y)
    return y

lr = 0.2
iters = 10000

for i in range(iters):
    y_pred = predict(x)
    loss = F.mean_squared_error(y, y_pred)

    # 各 Linear インスタンスのパラメータの勾配をまとめてリセット
    l1.cleargrads()
    l2.cleargrads()
    loss.backward()

    # 各 Linear インスタンスのパラメータを更新
    for l in [l1, l2]:
        for p in l.params():
            p.data -= lr * p.grad.data

    if i % 1000 == 0:
        print("(iter: ", i, ") loss: ", loss)
```